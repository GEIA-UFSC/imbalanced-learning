{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem level approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score as roc_auc, accuracy_score as acc\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standard classification model for the problem**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfc(train_X, train_Y, validation_X, validation_Y, seed=42):\n",
    "    \n",
    "    rfc = RFC(n_estimators=100, random_state=seed)\n",
    "    rfc = rfc.fit(train_X, train_Y)\n",
    "\n",
    "    print(\"Accuracy Score: {0:.2f}\".format(acc(validation_Y, rfc.predict(validation_X))))\n",
    "    print(\"ROC-AUC: {0:.2f}\".format(roc_auc(validation_Y, rfc.predict(validation_X))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unbalanced ratio: 15:1\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('./train_ZoGVYWq.csv')\n",
    "\n",
    "print('Unbalanced ratio: {}:1'.format(int(round(len(train[train.renewal==1])/len(train[train.renewal==0])))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data wrangling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns = train.columns.str.replace('-','_')\n",
    "train.fillna(train.mean().astype(int), inplace=True)\n",
    "\n",
    "train['n_unpaid'] = train.Count_3_6_months_late +train.Count_6_12_months_late + train.Count_more_than_12_months_late\n",
    "\n",
    "train = pd.merge(\n",
    "    train[train.columns[~train.columns.isin(train.select_dtypes(object))]], \n",
    "    pd.get_dummies(train.select_dtypes(object)), \n",
    "    left_index=True, right_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train and validation split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/artur/.virtualenvs/mckinsey-hackaton/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2069: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "train_X, validation_X, train_Y, validation_Y = train_test_split(train.drop(['renewal'], axis=1),\n",
    "                                               train['renewal'],\n",
    "                                               train_size = .8,\n",
    "                                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scale dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/artur/.virtualenvs/mckinsey-hackaton/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "# the independent variable doesn't need scaling since is comprised between 0 and 1\n",
    "train_Y = train_Y.values.reshape((len(train_Y),))\n",
    "validation_Y = validation_Y.values.reshape((len(validation_Y),))\n",
    "\n",
    "# scale values to range 0-1\n",
    "train_X = scaler.fit_transform(train_X)\n",
    "\n",
    "# don't `fit` the validation set, it must be replicated from the training dataset scaler\n",
    "validation_X = scaler.transform(validation_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.94\n",
      "ROC-AUC: 0.55\n"
     ]
    }
   ],
   "source": [
    "rfc(train_X, train_Y, validation_X, validation_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attempt to segment the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/artur/.virtualenvs/mckinsey-hackaton/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2069: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n",
      "/home/artur/.virtualenvs/mckinsey-hackaton/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "# split the dataset once again\n",
    "train_X, validation_X, train_Y, validation_Y = train_test_split(train.drop(['renewal'], axis=1),\n",
    "                                               train['renewal'],\n",
    "                                               train_size = .8,\n",
    "                                               )\n",
    "# determine the feature range for the predictor variables\n",
    "segment = train_X.loc[list(train_Y[train_Y==0].index),:].describe()\n",
    "\n",
    "# segment the training set based on the max-min limits\n",
    "for column in segment.columns:\n",
    "    train_X = train_X.loc[(train_X[column]<=segment.loc['max', column]) & (train_X[column]>=segment.loc['min', column])]\n",
    "\n",
    "train_Y = train_Y.loc[train_X.index]\n",
    "\n",
    "#scale data\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "train_Y = train_Y.values.reshape((len(train_Y),))\n",
    "validation_Y = validation_Y.values.reshape((len(validation_Y),))\n",
    "\n",
    "# scale values to range 0-1\n",
    "train_X = scaler.fit_transform(train_X)\n",
    "validation_X = scaler.transform(validation_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.94\n",
      "ROC-AUC: 0.56\n"
     ]
    }
   ],
   "source": [
    "rfc(train_X, train_Y, validation_X, validation_Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
